# Ripasso di Architettura dei Calcolatori

# Cache Memory

## 1. Anatomia dell'Indirizzo e della Cache

La CPU lavora con indirizzi virtuali/fisici (es. 32 bit). La Cache non vede l'indirizzo come un blocco unico, ma lo scompone in tre parti fondamentali.

$$Indirizzo (32 bit) = [ TAG \ \mid \ INDEX \ \mid \ OFFSET ]$$

### A. I Componenti

1.  **OFFSET**
    *   **Cos'è:** Indica *quale byte* all'interno della linea di cache vogliamo leggere.
    *   **Es:** *"Se ho una linea da 16B, significa che dentro possono starci 4 indirizzi da 4B (interi)"*
    *   **Calcolo:** $Bit_{Offset} = \log_2(\text{Dimensione Linea in Byte})$.
    *   **Località Spaziale:** Quando carichi un dato, carichi l'intera linea (es. 16 Byte). I vicini vengono caricati "gratis".

2.  **INDEX (Indice)**
    *   **Cos'è:** È il puntatore che ci dice *in quale riga* (o Set) della cache dobbiamo andare a guardare. È l'indirizzo della "scatola".
    *   **Calcolo:** $Bit_{Index} = \log_2(\text{Numero di Righe o Sets})$.

3.  **TAG (Etichetta)**
    *   **Cos'è:** È il documento di identità del dato. Serve a confermare se il dato trovato all'Index specificato è *davvero* quello che cercavamo o un altro che è capitato lì per caso.
    *   **Calcolo:** Bit rimanenti ($32 - Index - Offset$).

### B. Struttura Fisica: Dove stanno i dati?

*Dati* e *controlli* sono separati. La cache è composta da due memorie parallele:

1.  **Data Array (La Matrice dei Dati):** Contiene i blocchi veri e propri (es. i 16 Byte). Qui non ci sono indirizzi, solo valori.
2.  **Tag Directory (La Memoria di Supporto):** È affiancata ai dati.
    *   **Cosa salva:** Salva **SOLO il TAG** e i bit di stato (Valid, Dirty).
    *   **Cosa NON salva:** Non salva l'Index (perché l'Index è l'indirizzo della riga stessa) e non salva l'Offset (perché l'Offset serve solo a scegliere il byte dopo la lettura).

---

## 2. Direct Mapped vs. N-Way Associative

### Direct Mapped (Mappatura Diretta)
*   **Logica:** Ogni indirizzo di memoria ha **UN SOLO** posto possibile nella cache, determinato dall'Index.
*   **Metafora:** Un hotel dove la Stanza 101 ha **1 solo letto**.
*   **Eviction (Sfratto):** Se due variabili (`var1` e `var3`) hanno lo stesso Index ma Tag diverso, si "prendono a calci".
    *   Arriva `var3` -> Trova `var1` -> **Conflitto immediato** -> `var1` viene buttata fuori.
*   **Problema:** Alto tasso di miss da conflitto (Thrashing) anche se la cache è vuota altrove.

### N-Way Set Associative (Associativa a N Vie)
*   **Logica:** L'Index non punta più a una singola riga, ma a un **Insieme (SET)**. Ogni Set contiene **N Linee (Vie)**.
*   **Metafora:** Un hotel dove la Stanza 101 è una suite con **N letti**.
*   **Vantaggio:** Due variabili con lo stesso Index possono convivere pacificamente in vie diverse dello stesso Set.
*   **Geometria:** Rispetto alla Direct Mapped (a parità di dimensione totale):
    *   I Sets sono meno delle Linee totali ($Sets = Linee / N$).
    *   L'**Index diminuisce** di bit.
    *   Il **Tag aumenta** di bit.

---

## 3. Risoluzione Esercizio Passo-Passo

**Dati Comuni:**
*   Cache: 1 MB ($2^{20}$ B)
*   Linea: 16 Byte ($2^4$ B) -> **Offset = 4 bit**
*   Indirizzi Hex:
    *   `var1` (F000A023) -> Tag `F00...`
    *   `var2` (F000A021) -> Tag `F00...` (Stesso blocco di var1)
    *   `var3` (A000A022) -> Tag `A00...` (Blocco diverso)
    *   `var4` (F000A025) -> Tag `F00...` (Stesso blocco di var1)

### Parte A: Direct Mapped

1.  **Geometria:**
    *   Linee = $2^{20} / 16 = 2^{16}$.
    *   **Index = 16 bit** (`0A02` per tutte le variabili).
    *   **Tag = 12 bit**.

2.  **Simulazione Iterazione 1:**
    *   `var1` (F...): Cache vuota. **Miss Compulsory**. Carico F. (Cache: `[F]`)
    *   `var2` (F...): Tag F c'è. **Hit**.
    *   `var3` (A...): Tag F occupa la riga. Conflitto. **Miss Compulsory**. Butto F, carico A. (Cache: `[A]`)
    *   `var4` (F...): Tag A occupa la riga. Conflitto. **Mis Conflict**. Butto A, carico F. (Cache: `[F]`)

3.  **Iterazioni successive:**
    *   Si ripete il ciclo di conflitti tra `var3` e le altre.
    *   Risultato: **2 Hit, 2 Miss** per ciclo.

### Parte B: 2-Way Set Associative

1.  **Geometria:**
    *   Sets = $2^{16} / 2 = 2^{15}$.
    *   **Index = 15 bit**.
    *   **Tag = 13 bit** (aumenta di 1).

2.  **Analisi:** Tutte le variabili cadono nello stesso Set, ma abbiamo solo **2 Blocchi unici** in gioco: il blocco `F...` (per var1, var2, var4) e il blocco `A...` (per var3). Il Set ha 2 vie, quindi **ci stanno entrambi**.

3.  **Simulazione Iterazione 1:**
    *   `var1` (Blocco F): Set vuoto. **Miss**. Metto F in Via 0.
    *   `var2` (Blocco F): C'è in Via 0. **Hit**.
    *   `var3` (Blocco A): Via 0 occupata, Via 1 libera. **Miss**. Metto A in Via 1.
    *   `var4` (Blocco F): C'è in Via 0. **Hit**. *(Nota: Qui non c'è sostituzione perché var1 e var4 sono lo stesso blocco!)*.

4.  **Iterazioni Successive (2-10):**
    *   Il Set contiene `[ Via 0: F ] [ Via 1: A ]`.
    *   Tutte le variabili trovano il loro Tag.
    *   **4 Hit, 0 Miss**.

---

## 4. LRU

Abbiamo visto che nella 2-Way, con i blocchi `F00` e `A00`, la cache è piena ma stabile. Quando avviene una **vera Conflict Miss** con sostituzione LRU?

**Scenario:**
Il Set `0A02` è pieno:
*   Via 0: Tag `F00` (usato recentemente)
*   Via 1: Tag `A00` (usato meno recentemente)

**Arriva un nuovo accesso:** `var5` all'indirizzo `D000A020`.
1.  **Index:** `0A02` (Stesso Set).
2.  **Tag:** `D00` (Nuovo!).
3.  **Controllo:** L'hardware cerca `D00` nel Set. Non c'è. Le vie sono piene.
4.  **Risultato:** **CONFLICT MISS**.

**Intervento della Policy LRU (Least Recently Used):**
L'hardware deve fare un'**EVICTION** (Sfratto).
*   Controlla i bit LRU: chi tra `F00` e `A00` non viene toccato da più tempo?
*   Supponiamo sia `A00`.
*   **Azione:**
    1.  Elimina il Tag `A00` dalla Via 1.
    2.  Elimina l'intero blocco di dati (16 Byte) associato ad `A00`.
    3.  Scrive il Tag `D00` nella Via 1.
    4.  Carica i 16 Byte del blocco `D...` nella Via 1.

**nota fondamentale:** 
L'eviction lavora sempre a livello di linea (Blocco), mai a livello di singola variabile (Word).  


## 1. La Control Unit (CU)
La **Control Unit** è il componente della CPU responsabile della gestione e del coordinamento delle operazioni del processore. A differenza della **ALU** (Arithmetic Logic Unit), che esegue materialmente i calcoli, la CU agisce come "cervello" o supervisore.

*   **Funzione:** Decodifica le istruzioni provenienti dalla memoria e invia segnali di controllo agli altri componenti (ALU, Registri, Bus, Memoria) per eseguire l'operazione richiesta.
*   **Ciclo Macchina:** La CU orchestra le tre fasi fondamentali:
    1.  **Fetch:** Preleva l'istruzione dalla *Instruction Memory*.
    2.  **Decode:** Interpreta i bit dell'istruzione per capire quale operazione eseguire.
    3.  **Execute:** Attiva i circuiti necessari (es. dice alla ALU di sommare o ai registri di caricare dati).
*   **Vantaggio in SIMD:** Nelle architetture SIMD (es. GPU), una singola Control Unit gestisce simultaneamente molteplici ALU (Processing Elements). Questo riduce drasticamente l'area del chip e il consumo energetico, poiché l'overhead di Fetch e Decode viene pagato una sola volta per un intero vettore di dati.

## 2. ISA (Instruction Set Architecture) e RISC-V
L'**ISA** rappresenta l'interfaccia astratta tra l'hardware (CPU) e il software (Compilatore). Definisce l'insieme di istruzioni che il processore è in grado di comprendere ed eseguire nativamente.

*   **RISC-V:** È un'ISA di tipo **RISC** (Reduced Instruction Set Computer) open-source.
    *   *Caratteristiche:* Utilizza un set di istruzioni semplice e regolare, ideale per implementazioni hardware efficienti e pipeline ottimizzate.


## 3. Gerarchia e Organizzazione della Memoria
Sebbene risiedano fisicamente nella stessa RAM (DRAM), logicamente e a livello di Cache L1, si distinguono due aree di memoria fondamentali:

*   **Instruction Memory (Text Segment):**
    *   Contiene il codice binario del programma (le istruzioni da eseguire).
    *   È generalmente di sola lettura (Read-Only) per prevenire modifiche accidentali o malevole al codice.
    *   Viene indirizzata dal registro **PC (Program Counter)**.
*   **Data Memory:**
    *   Contiene i dati su cui il programma opera (Variabili globali, Heap, Stack).
    *   È scrivibile e leggibile (Read/Write).
    *   Viene acceduta tramite istruzioni di Load (lettura) e Store (scrittura) calcolando gli indirizzi efficaci.

## 4. Architetture a 32-bit vs 64-bit
La dicitura "architettura a 64 bit" (es. RV64) definisce la larghezza dei registri generali e dello spazio di indirizzamento, non necessariamente la lunghezza delle istruzioni.

*   **Ampiezza Dati e Indirizzi (64-bit):**
    *   I registri generali (es. `x0` - `x31`) sono larghi 64 bit (8 Byte).
    *   I puntatori di memoria sono a 64 bit, permettendo di indirizzare una quantità di RAM virtualmente illimitata (essenziale per applicazioni HPC e AI che richiedono dataset massivi).
    *   Tipi di dato come `double` (8 Byte) o `long long` sono gestiti nativamente in un singolo registro.

*   **Lunghezza Istruzioni (32-bit):**
    *   Anche nelle macchine a 64 bit (come RISC-V 64 o ARM64), le istruzioni standard hanno tipicamente una lunghezza fissa di **32 bit (4 Byte)**.
    *   *Motivazione:* Mantenere le istruzioni compatte migliora la *Code Density* (densità del codice), permettendo di memorizzare più istruzioni nella Cache L1 Instruction e riducendo i cache miss.

*   **Comportamento del Program Counter (PC):**
    *   Poiché le istruzioni sono lunghe 4 Byte, il PC viene incrementato di 4 unità alla volta (`PC = PC + 4`) per passare all'istruzione successiva, indipendentemente dal fatto che la macchina sia a 32 o 64 bit.


* **CISC**:
    * L'architettura CISC differisce dal numero di byte dedicati alle istruzioni, **non** è fisso bensì **variabile**!  
    Un'istruzione potrebbe essere lunga 1B (es:return) o 15B (una mov complessa).  
    * CISC è l'architettura utilizzata da x86/Intel/AMD  

---


## 5. Endian
La memoria è indirizzata a **Byte** (ogni indirizzo di memoria contiene 8 bit). Tuttavia, i dati che usiamo spesso occupano più byte (es. un `int` occupa 4 byte).
L'**Endianness** definisce l'ordine in cui questi 4 byte vengono disposti in memoria, dal "più significativo" al "meno significativo".

### Concetti Preliminari: MSB vs LSB
Prendiamo il numero esadecimale (32 bit): `0x12345678`.
*   **MSB (Most Significant Byte):** È la parte che "vale di più". Qui è `0x12` (come le migliaia in un numero decimale).
*   **LSB (Least Significant Byte):** È la parte che "vale di meno". Qui è `0x78` (come le unità).

### Big Endian vs Little Endian
Supponiamo di voler salvare `0x12345678` all'indirizzo di memoria `0x100`.

1.  **Big Endian (La fine grande per prima)**
    *   Il byte più significativo (MSB) va all'indirizzo più basso.
    *   È il modo "naturale" in cui noi umani leggiamo i numeri (da sinistra a destra).
    *   *Esempio:* Reti TCP/IP (Network Byte Order).

    | Indirizzo | Dato |
    | :--- | :--- |
    | 0x100 | **12** (MSB) |
    | 0x101 | 34 |
    | 0x102 | 56 |
    | 0x103 | **78** (LSB) |

2.  **Little Endian (La fine piccola per prima)**
    *   Il byte meno significativo (LSB) va all'indirizzo più basso.
    *   È lo standard per **Intel/AMD x86** e spesso la scelta di default per **RISC-V**.
    *   *Vantaggio:* Se vuoi leggere solo il byte meno significativo (cast a `char`), leggi semplicemente l'indirizzo base senza dover fare calcoli (è già lì all'inizio).

    | Indirizzo | Dato |
    | :--- | :--- |
    | 0x100 | **78** (LSB) |
    | 0x101 | 56 |
    | 0x102 | 34 |
    | 0x103 | **12** (MSB) |



---

## 6. Organizzazione della Memoria Dati: Stack vs Heap
Entrambe risiedono nella RAM (Data Memory), ma hanno scopi e gestioni opposte.

### Stack (La Pila)
*   **Cos'è:** Una memoria LIFO (Last In, First Out) usata per la gestione delle chiamate a funzione.
*   **Cosa contiene:**
    *   Variabili locali delle funzioni (`int i`, `char buf[10]`).
    *   Indirizzi di ritorno (dove deve tornare la CPU finita la funzione).
    *   Parametri passati alla funzione.
*   **Gestione:** **Automatica**. Viene gestita dal compilatore. Quando chiami una funzione, lo spazio viene creato ("Pushed"); quando la funzione termina, lo spazio viene distrutto ("Popped").
*   **Velocità:** Estremamente veloce (basta spostare un registro chiamato *Stack Pointer*).
*   **Limiti:** Ha una dimensione fissa e limitata (di solito pochi MB). Se superi il limite (es. ricorsione infinita), ottieni uno **Stack Overflow**.
*   **Direzione:** Nelle architetture moderne (x86, RISC-V), lo Stack cresce "verso il basso" (dagli indirizzi di memoria alti verso quelli bassi).

### Heap 
*   **Cos'è:** Un'area di memoria disordinata usata per l'allocazione dinamica.
*   **Cosa contiene:** Dati che devono sopravvivere anche dopo la fine della funzione che li ha creati (oggetti complessi, array di dimensione variabile, strutture dati di grandi dimensioni).
*   **Gestione:** **Manuale** (in C/C++).
    *   Si richiede spazio con `malloc()` o `new`.
    *   Si libera spazio con `free()` o `delete`.
    *   *Nota:* Se dimentichi di liberare, crei un **Memory Leak**.
*   **Velocità:** Più lenta dello Stack. Richiede un algoritmo (allocator) per cercare un buco libero di dimensione adeguata nella RAM.
*   **Direzione:** Di solito cresce "verso l'alto" (dagli indirizzi bassi verso quelli alti), andando incontro allo Stack.

### Tabella Riassuntiva

| Caratteristica | Stack | Heap |
| :--- | :--- | :--- |
| **Durata Dati** | Temporanea (finché la funzione è attiva) | Persistente (finché non fai `free`) |
| **Gestione** | Automatica (CPU/Compilatore) | Manuale (Programmatore) |
| **Velocità** | Molto Alta | Media/Bassa |
| **Problema Tipico**| Stack Overflow | Memory Leak / Fragmentation |