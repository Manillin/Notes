# General things to learn & know
 

- co scheduling: (a livello di sys admin)  
    Massimizzare l'uso delle risorse dividendo un nodo in 2 blocchi (tipo processo che usa solo CPU puoi carve out una partition di tot core, e avere i core gpu rimanenti) 

- usare il compilatore, i test su thea vanno compilati 
- CCL per GPU -> librerie per comunicazione tra GPU (reduce, alltoall) NCCL (test che si possono fare)  

- saper creare modulefiles custom 
- OSU benchmark per testare la rete e le GPU 



### Comandi Utili:

- sinfo: fa vedere i nodi del cluster
- squeue: fa vedere lo stato dei job

- salloc -p <nome_partizione> -N <num_nodi> 

- nvidia-smi [-q]  
    Informazioni sul nodo e fa vedere cosa usano i job (si possono monitorare con 'watch') 

- ibstat 

- module av 






shared file systems :
Luster - high performance 
NFS (NAS?) - base (low performance) 


in un cluster production level la home directory è su un file system low performance come NAS (non si invitano gli utenti a usare la home dir come HP storage).  

Module files -> settano variabili di ambiente per farle puntare a uno specifico sw environment   
LD_LIBRARY: librerie
CPATH e C_INCLUDE_PATH: header files   
Si possono creare autonomamente, nvidia fornisce i default tramite nvhpc-hpcx 
- hpcx ha solo le communication libraries 
- nvhpc ha communication libraries + tutto il sw stack per far girare l'applicazione 
per caricare un modulo: `ml load nvhpc/25.5`    
per vedere la lista di module file caricati in un determinato momento: `ml list`
per pulire l'ambiente: `ml unload nvhpc/25.5`

I module file sono un grande vantaggio rispetto all'uso di export PATH=/....    


--- 

Creazione di Job su slurm con uno script bash   

OSU benchmarks per testare la rete ma anche per testare la GPU (mosta un job su script che fa questo benchmark), molto facili da compilare.  
Prima di dare un cluster agli utenti è buona norma controllare bandwidth e latency per vedere se rispettano i valori standard per il tipo di connessione che si ha a disposizione.   

Una volta creato lo script bash si lancia con `sbatch nome-script.sh`, una volta finito il job avremo i file .out e .err (con i nomi che abbiamo usato per definirli dentro lo script)


--- 

parte di networking 

per controllare che tipo di connessione abbiamo nel cluster: `ibstat` (infiniband status)
fornisce la lista delle schede di rete HCA (host channel adapter) che sono le schede di rete per la connessione a infiniband