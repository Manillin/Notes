# Synchronization 


Un thread è l'astrazione di un programma dinamico in esecuzione, in un programma parallelo i thread possono essere creati in maniera dinamica (fork da un thread gia esistente)  

Un thread ha un insieme di variabili private (come lo stack: memoria automatica) e un insieme di variabili shared (oggetti visibili a tutti i thread)  

I Thread comunicano **implicitamente** quando leggono e scrivono su variabili condivise  
I Thread si coordinano **sincronizzando** le variabili condivise  


![shared and priv mem](../../images/shared&priv_mem.png)


### Race condition


```c++
static ins s = 0;

#THREAD1
for (i = 0,i++,(n/2)-1){
    s = s + sqr(A[i])
}

#THREAD2
for (i=n/2;i++;n-1){
    s = s+ sqr(A[i])
}
```

Nello snippet di codice si presenta una **Race Condition** sulla variabile `s` del programma (che è visibile da entrambi i thread, mentre la variabile `i` è privata su ciascun thread).  

Una _**Race Condition**_ avviene quando:
-  Due thread mappati su due processori accedono alla stessa variabile e almeno uno dei due ci scrive dentro 
- Gli accessi sono concorrenti (non sincronizzati) e quindi potrebbero accadere simultaneamente  


### Operazioni Atomiche

Per comprendere un programma concorrente bisogna conoscere le operazioni indivisibili (atomiche) sottostanti

- **Atomic Operation:** Un operazione che esegue fino al completamento o non esegue proprio
    - È indivisibile: non può essere arrestata e non può essere modificata da nessuno mentre esegue
    - È il _BuildingBlock_ in quanto se non esistessero operazioni atomiche non si avrebbero modi per fare lavorare insieme i thread.  

### Definizioni: 

1. _**Sincronizzazione:**_ Usa operazioni atomiche per assicurare la cooperazione tra Thread 
2. _**Mutual Exclusion:**_ Assicura che un unico Thread faccia una task in un particolare istante: un Thread esclude gli altri mentre fa la propria task
3. _**Critical Section:**_ Pezzo di codice che **solo** un unico Thread può eseguire in un momento
    - Critical Section definisce la granularità di condivisione tra Thread
4. _**Lock:**_ Impedisce a qualcuno di fare qualcosa
    - Si mette un lock prima di entrare in Critical Sections e prima di accedere a dati condivisi 
    - Si fa unlock quando si esce una volta acceduto il dato shared
    - Si aspetta se si trova un lock 


### Implementazione di un `lock` con `test&set`:

Il `lock` deve essere atomico, quindi indivisibile, per andare in contro a questa evenienza si fanno istruzioni hardware dedicate.

```c++
test&set(&address){ 
    // address mi rappresenta l'indirizzo che ha il valore del lock 
    result = M[address];
    M[address] = 1;
    return result;
}
```

Soluzione semplice:

```c++
int value = 0;
// Acquire -> lock 
Acquire() {
    while (test&set(value)); //while busy 
}
// Release -> unlock 
Relese() {
    value = 0;
}
```

**Importante:** La sezione di codice tra `Acquire()` e `Release()` è chiamata **`Critical Section`**  

Come cambia l'esempio della race condition sfruttando il lock e la privatizzazione di una variabile locale:

```c++
static int s = 0;

#THREAD1
local_s1 = 0
for (i=0;i++;n/2-1){
    local_s1 = local_s1 + sqr(A[i])
}
lock();
s = s + local_s1; //Critical section
unlock();

#THREAD2
local_s2 = 0
for (i=n/2;i++;n-1){
    local_s2 = local_s2 + sqr(A[i])
}
lock();
s = s + local_s2; //Critical section
unlock();
```

### Criteri di performance per operazioni di sincronizzazione

1. **Latenza:** Tempo minimo per acquisire il lock se non c'è contenzione (quanto ci impiega un thread a fare il lock).  È rilevante in casi di contenzione bassa (pochi thread che competono)

2. **Bandwidth:** Operazioni di sincronizzazione al secondo sotto alta contenzione tra i thread

3. **Traffico:** Numero di eventi generati come invalidazione della cache, accessi alla memoria e scambi di messaggi. Più thread competono per il lock e più eventi verranno generati saturando il sistema di comunicazione.  Rilevante in particolar modo in sistemi con risorse condivise limitate.  

4. **Storage:** Memoria necessaria per rappresentare il lock e le sue strutture di supporto, più thread concorrono sul lock più memoria è necessaria. Particolarmente rilevante in sistemi embedded a memoria limitata

5. **Fairness:** Capacità del sistema di garantire che tutti i thread abbiano una possibilità _equa_ di accedere alla risorsa condivisa.  Rilevante in applicazioni che richiedono un comportamento _prevedibile_ come sistemi in tempo reale.  

currently @ 1:07 





```asm
// atomically load mem[addr] into R0 and set mem[addr] to 1
ts R0, mem[addr] 

lock:
    ts R0, mem[addr] //load word into R0
    bnz R0, #0       //if 0, lock obtained

unlock:
    st mem[addr], #0 // store 0 to address 

```

Questa implementazione di `test&set` genera tanto traffico, perchè sto mettendo nel mio programma una sequenza potenzialmente lunghissima di test e jump, problematico perchè se guardiamo il traffico delle transazioni (*traffico di coerenza della cache*) ci rendiamo conto che invalidiamo le linee di cache per i processori che provano ad acquisire il lock.  
Il problema è quindi che in maniera continuativa sto andando a disturbare il protocollo di cache


![test and set cache coherence traffic](../../images/testandset_cache_traffic.png)


Bisogna trovare un modo per rendere più 'snella' questa operazione

### Test&Test&Set Lock :

Prima faccio un test, e solo quando il primo test mi dice che ho le condizioni per fare la test&set la eseguo (in quanto è relativamente costosa).  


```c++

void Lock(volatile int* lock){
    while(1){
        while(*lock != 0);
        if (test&set(*lock) == 0)
    }
}

void Unlock(volatile int* lock){
    *lock = 0;
}
```

Viene implementato con un `while(*lock != 0)`, che è una normale lettura. Lo controllo con una primitiva che non costa tanto (leggo la variabile `*lock` in maniera tradizionale, che ho in cache).   
Continuo quindi a leggere il valore del lock in cache, tale valore cambierà solamente quando qualcuno farà release, in quanto:
- Quando un thread fa release, il protocollo di cache coherence mi avviserà che il dato di `*lock` in cache è invalido, e a quel punto avrò il segnale che è cambiato il valore di quella variabile, e potrò fare la mia `test&set`, se riesco ad ottenre il lock, atomicamente lo blocco, se non riesco riparto dal controllare il valore di `*lock` in cache che costa poco.  

La problematica di Fairness è ancora presente, ma garantisco di non impestare il sistema di bus con tante transazioni come illustrato dall'immagine sottostante.  


![test&test&set](../../images/testandtestandset.png)




# Consistency:

La consistenza è una problematica che va uno step oltre la coerenza (di cache), in quanto non si tratta soltanto che i valori vengano correttamente propagati ma si tratta di definire una tempistica con cui la propagazione avviene.  
I memory consistency models definiscono dei worst case al tempo con cui riteniamo lecito che il ritardo di propagazione avvenga.   

